# ----------------------------------------------------------------------------------------------------------------------
# THREE-WAY ML COMPARISON: Neural Network vs K-Fold vs Gaussian Process
# Compares all three ML algorithms on dynamics prediction accuracy
# ----------------------------------------------------------------------------------------------------------------------
import sys
sys.path.append('fnc/simulator')
sys.path.append('fnc/controller')
sys.path.append('fnc')

import matplotlib.pyplot as plt
from plot import plotTrajectory, plotClosedLoopLMPC, animation_xy
from initControllerParameters import initMPCParams, initLMPCParams
from PredictiveControllers import MPC, LMPC
from PredictiveModel import PredictiveModel
from Utilities import Regression, PID
from SysModel import Simulator
from Track import Map
from NeuralNetworkDynamics import NNDynamicsPredictor
from KFoldDynamics import KFoldDynamicsPredictor
from GaussianProcessDynamics import GPDynamicsPredictor
import numpy as np
import os

def main():
    print("\n" + "="*100)
    print(" "*15 + "THREE-WAY ML COMPARISON: Neural Network vs K-Fold vs Gaussian Process")
    print("="*100 + "\n")
    
    # Setup
    N, n, d = 14, 6, 2
    x0 = np.array([0.5, 0, 0, 0, 0, 0])
    xS = [x0, x0]
    dt, vt = 0.1, 0.8
    map = Map(0.4)

    print(f"Configuration:")
    print(f"  - Track Length: {map.TrackLength:.2f} m")
    print(f"  - Target Velocity: {vt} m/s\n")

    mpcParam, ltvmpcParam = initMPCParams(n, d, N, vt)
    numSS_it, numSS_Points, Laps, _, QterminalSlack, lmpcParameters = initLMPCParams(map, N)
    
    simulator = Simulator(map)
    LMPCsimulator = Simulator(map, multiLap=False, flagLMPC=True)
    
    os.makedirs("models", exist_ok=True)
    
    # ======================================================================================================================
    # INITIALIZE ALL THREE ML MODELS
    # ======================================================================================================================
    print("="*100)
    print("INITIALIZING THREE ML MODELS")
    print("="*100 + "\n")
    
    nn_predictor = NNDynamicsPredictor(state_dim=n, input_dim=d, hidden_dim=256, learning_rate=1e-3, device='cpu')
    kfold_predictor = KFoldDynamicsPredictor(state_dim=n, input_dim=d, n_folds=5)
    gp_predictor = GPDynamicsPredictor(state_dim=n, input_dim=d, noise_level=0.01)
    
    print("âœ“ Neural Network: 256 hidden units")
    print("âœ“ K-Fold: 5 folds with Ridge regression")
    print("âœ“ Gaussian Process: RBF kernel\n")

    # ======================================================================================================================
    # COLLECT BASELINE DATA
    # ======================================================================================================================
    print("="*100)
    print("COLLECTING BASELINE DATA")
    print("="*100 + "\n")
    
    # PID
    PIDController = PID(vt)
    xPID, uPID, xPID_glob, _ = simulator.sim(xS, PIDController)
    pid_time = xPID.shape[0] * dt
    print(f"âœ“ PID: {pid_time:.2f}s ({xPID.shape[0]} samples)")
    
    nn_predictor.add_trajectory(xPID, uPID)
    kfold_predictor.add_trajectory(xPID, uPID)
    gp_predictor.add_trajectory(xPID, uPID)

    # MPC
    A, B, _ = Regression(xPID, uPID, 1e-7)
    mpcParam.A, mpcParam.B = A, B
    mpc = MPC(mpcParam)
    xMPC, uMPC, xMPC_glob, _ = simulator.sim(xS, mpc)
    mpc_time = xMPC.shape[0] * dt
    print(f"âœ“ MPC: {mpc_time:.2f}s ({xMPC.shape[0]} samples)")
    
    nn_predictor.add_trajectory(xMPC, uMPC)
    kfold_predictor.add_trajectory(xMPC, uMPC)
    gp_predictor.add_trajectory(xMPC, uMPC)

    # TV-MPC
    predictiveModel = PredictiveModel(n, d, map, 1)
    predictiveModel.addTrajectory(xPID, uPID)
    ltvmpcParam.timeVarying = True
    mpc = MPC(ltvmpcParam, predictiveModel)
    xTVMPC, uTVMPC, xTVMPC_glob, _ = simulator.sim(xS, mpc)
    tvmpc_time = xTVMPC.shape[0] * dt
    print(f"âœ“ TV-MPC: {tvmpc_time:.2f}s ({xTVMPC.shape[0]} samples)\n")
    
    nn_predictor.add_trajectory(xTVMPC, uTVMPC)
    kfold_predictor.add_trajectory(xTVMPC, uTVMPC)
    gp_predictor.add_trajectory(xTVMPC, uTVMPC)

    total_samples = len(nn_predictor.all_states)
    print(f"ğŸ“Š Total training samples: {total_samples}\n")

    # ======================================================================================================================
    # TRAIN ALL THREE ML MODELS
    # ======================================================================================================================
    print("="*100)
    print("TRAINING ALL THREE ML MODELS")
    print("="*100 + "\n")
    
    print("1ï¸âƒ£ Training Neural Network...")
    print("-" * 80)
    nn_predictor.train(epochs=200, batch_size=128, verbose=True)
    nn_predictor.save_model("models/nn_model.pth")
    
    print("\n2ï¸âƒ£ Training K-Fold Cross-Validation...")
    print("-" * 80)
    kfold_predictor.train(verbose=True)
    kfold_predictor.save_model("models/kfold_model.pkl")
    
    print("3ï¸âƒ£ Training Gaussian Process...")
    print("-" * 80)
    gp_predictor.train(verbose=True)
    gp_predictor.save_model("models/gp_model.pkl")

    # ======================================================================================================================
    # PREDICTION ACCURACY COMPARISON
    # ======================================================================================================================
    print("="*100)
    print("PREDICTION ACCURACY COMPARISON")
    print("="*100 + "\n")
    
    n_test = min(200, len(xPID) - 1)
    test_idx = np.random.choice(len(xPID) - 1, n_test, replace=False)
    
    print(f"Testing on {n_test} random samples...\n")
    
    errors_baseline = []
    errors_nn = []
    errors_kfold = []
    errors_gp = []
    
    for idx in test_idx:
        true_next = xPID[idx + 1]
        
        # Baseline
        pred_baseline = A @ xPID[idx] + B @ uPID[idx]
        errors_baseline.append(np.abs(pred_baseline - true_next))
        
        # Neural Network
        pred_nn = nn_predictor.predict(xPID[idx], uPID[idx])
        errors_nn.append(np.abs(pred_nn - true_next))
        
        # K-Fold
        pred_kfold = kfold_predictor.predict(xPID[idx], uPID[idx], return_std=False)
        errors_kfold.append(np.abs(pred_kfold - true_next))
        
        # Gaussian Process
        pred_gp, _ = gp_predictor.predict(xPID[idx], uPID[idx], return_std=True)
        errors_gp.append(np.abs(pred_gp - true_next))
    
    # Compute MAE
    mae_baseline = np.mean(errors_baseline, axis=0)
    mae_nn = np.mean(errors_nn, axis=0)
    mae_kfold = np.mean(errors_kfold, axis=0)
    mae_gp = np.mean(errors_gp, axis=0)
    
    state_names = ['vx', 'vy', 'wz', 'epsi', 's', 'ey']
    
    print("Mean Absolute Error per state:")
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚  State  â”‚  Baseline  â”‚     NN     â”‚   K-Fold   â”‚     GP     â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    
    for i, name in enumerate(state_names):
        print(f"â”‚ {name:7s} â”‚ {mae_baseline[i]:10.6f} â”‚ {mae_nn[i]:10.6f} â”‚ {mae_kfold[i]:10.6f} â”‚ {mae_gp[i]:10.6f} â”‚")
    
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")
    
    # Overall
    overall_baseline = np.mean(mae_baseline)
    overall_nn = np.mean(mae_nn)
    overall_kfold = np.mean(mae_kfold)
    overall_gp = np.mean(mae_gp)
    
    imp_nn = ((overall_baseline - overall_nn) / overall_baseline) * 100
    imp_kfold = ((overall_baseline - overall_kfold) / overall_baseline) * 100
    imp_gp = ((overall_baseline - overall_gp) / overall_baseline) * 100
    
    print("Overall Comparison:")
    print(f"  Baseline (Linear):    {overall_baseline:.6f} (0.0%)")
    print(f"  Neural Network:       {overall_nn:.6f} ({imp_nn:+.1f}%)")
    print(f"  K-Fold CV:            {overall_kfold:.6f} ({imp_kfold:+.1f}%)")
    print(f"  Gaussian Process:     {overall_gp:.6f} ({imp_gp:+.1f}%)\n")
    
    # Winner
    methods = {'Neural Network': overall_nn, 'K-Fold': overall_kfold, 'Gaussian Process': overall_gp}
    winner = min(methods, key=methods.get)
    winner_score = methods[winner]
    winner_imp = ((overall_baseline - winner_score) / overall_baseline) * 100
    
    print(f"ğŸ† WINNER: {winner}")
    print(f"   Best MAE: {winner_score:.6f} ({winner_imp:+.1f}% better than baseline)\n")

    # ======================================================================================================================
    # UNCERTAINTY QUANTIFICATION
    # ======================================================================================================================
    print("="*100)
    print("UNCERTAINTY QUANTIFICATION (K-Fold vs GP)")
    print("="*100 + "\n")
    
    uncertainties_kfold = []
    uncertainties_gp = []
    
    for idx in test_idx[:50]:
        _, std_kfold = kfold_predictor.predict(xPID[idx], uPID[idx], return_std=True)
        _, std_gp = gp_predictor.predict(xPID[idx], uPID[idx], return_std=True)
        
        uncertainties_kfold.append(np.mean(std_kfold))
        uncertainties_gp.append(np.mean(std_gp))
    
    print(f"Average uncertainty across 50 test samples:")
    print(f"  K-Fold:  {np.mean(uncertainties_kfold):.6f} (ensemble disagreement)")
    print(f"  GP:      {np.mean(uncertainties_gp):.6f} (Bayesian posterior)\n")

    # ======================================================================================================================
    # RUN STANDARD LMPC
    # ======================================================================================================================
    print("="*100)
    print("RUNNING STANDARD LMPC (Reference)")
    print("="*100 + "\n")
    
    lmpcModel = PredictiveModel(n, d, map, 4)
    for i in range(4):
        lmpcModel.addTrajectory(xPID, uPID)
    
    lmpcParameters.timeVarying = True
    lmpc = LMPC(numSS_Points, numSS_it, QterminalSlack, lmpcParameters, lmpcModel)
    for i in range(4):
        lmpc.addTrajectory(xPID, uPID, xPID_glob)
    
    xS_lmpc = [x0, x0]
    lap_times_lmpc = []
    
    for it in range(numSS_it, min(Laps, numSS_it+10)):
        xL, uL, xL_glob, xS_lmpc = LMPCsimulator.sim(xS_lmpc, lmpc)
        lmpc.addTrajectory(xL, uL, xL_glob)
        lmpcModel.addTrajectory(xL, uL)
        lap_times_lmpc.append(lmpc.Qfun[it][0] * dt)
        print(f"  Lap {it}: {lap_times_lmpc[-1]:.2f}s")
    
    best_lmpc = min(lap_times_lmpc)
    avg_lmpc = np.mean(lap_times_lmpc)
    print(f"\nâœ“ Standard LMPC: Best={best_lmpc:.2f}s, Avg={avg_lmpc:.2f}s\n")

    # ======================================================================================================================
    # VISUALIZATION
    # ======================================================================================================================
    print("="*100)
    print("GENERATING VISUALIZATIONS")
    print("="*100 + "\n")
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # Plot 1: Per-State Accuracy
    x_pos = np.arange(len(state_names))
    width = 0.2
    
    ax1.bar(x_pos - 1.5*width, mae_baseline, width, label='Baseline', color='gray', alpha=0.7)
    ax1.bar(x_pos - 0.5*width, mae_nn, width, label='Neural Network', color='darkgreen', alpha=0.8)
    ax1.bar(x_pos + 0.5*width, mae_kfold, width, label='K-Fold', color='steelblue', alpha=0.8)
    ax1.bar(x_pos + 1.5*width, mae_gp, width, label='Gaussian Process', color='darkorange', alpha=0.8)
    
    ax1.set_ylabel('Mean Absolute Error', fontsize=12, fontweight='bold')
    ax1.set_title('Prediction Accuracy by State', fontsize=14, fontweight='bold')
    ax1.set_xticks(x_pos)
    ax1.set_xticklabels(state_names)
    ax1.legend(fontsize=10)
    ax1.grid(True, alpha=0.3, axis='y')
    ax1.set_yscale('log')
    
    # Plot 2: Overall Comparison
    methods_names = ['Baseline', 'Neural Net', 'K-Fold', 'Gaussian Proc']
    overall_errors = [overall_baseline, overall_nn, overall_kfold, overall_gp]
    colors = ['gray', 'darkgreen', 'steelblue', 'darkorange']
    
    bars = ax2.bar(methods_names, overall_errors, color=colors, alpha=0.8, edgecolor='black', linewidth=2)
    ax2.set_ylabel('Overall MAE', fontsize=12, fontweight='bold')
    ax2.set_title('Overall Prediction Accuracy', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')
    
    for bar, error in zip(bars, overall_errors):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{error:.5f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # Plot 3: Improvement Percentage
    improvements = [0, imp_nn, imp_kfold, imp_gp]
    
    bars = ax3.bar(methods_names, improvements, color=colors, alpha=0.8, edgecolor='black', linewidth=2)
    ax3.axhline(y=0, color='black', linestyle='-', linewidth=1)
    ax3.set_ylabel('Improvement over Baseline (%)', fontsize=12, fontweight='bold')
    ax3.set_title('Relative Improvement', fontsize=14, fontweight='bold')
    ax3.grid(True, alpha=0.3, axis='y')
    
    for bar, imp in zip(bars, improvements):
        height = bar.get_height()
        offset = 2 if height > 0 else -5
        ax3.text(bar.get_x() + bar.get_width()/2., height + offset,
                f'{imp:+.1f}%', ha='center', va='bottom' if height > 0 else 'top', 
                fontsize=11, fontweight='bold')
    
    # Plot 4: Uncertainty Comparison
    ax4.plot(range(len(uncertainties_kfold)), uncertainties_kfold, '-', 
             linewidth=2.5, label='K-Fold (Ensemble)', color='steelblue', alpha=0.8)
    ax4.plot(range(len(uncertainties_gp)), uncertainties_gp, '-', 
             linewidth=2.5, label='Gaussian Process (Bayesian)', color='darkorange', alpha=0.8)
    ax4.fill_between(range(len(uncertainties_kfold)), 0, uncertainties_kfold, 
                     alpha=0.2, color='steelblue')
    ax4.fill_between(range(len(uncertainties_gp)), 0, uncertainties_gp, 
                     alpha=0.2, color='darkorange')
    ax4.set_xlabel('Test Sample Index', fontsize=12, fontweight='bold')
    ax4.set_ylabel('Prediction Uncertainty', fontsize=12, fontweight='bold')
    ax4.set_title('Uncertainty Quantification Comparison', fontsize=14, fontweight='bold')
    ax4.legend(fontsize=11)
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('Three_Way_ML_Comparison.png', dpi=150, bbox_inches='tight')
    print("âœ“ Saved: Three_Way_ML_Comparison.png\n")
    
    plotClosedLoopLMPC(lmpc, map)
    
    # ======================================================================================================================
    # FINAL SUMMARY TABLE
    # ======================================================================================================================
    print("="*100)
    print("FINAL RESULTS SUMMARY")
    print("="*100 + "\n")
    
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚       Method         â”‚  Overall MAE    â”‚ Improvement (%)  â”‚   Features    â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"â”‚ Baseline (Linear)    â”‚   {overall_baseline:.6f}     â”‚      0.0%        â”‚   Simple      â”‚")
    print(f"â”‚ Neural Network       â”‚   {overall_nn:.6f}     â”‚     {imp_nn:+5.1f}%       â”‚ Deep Learning â”‚")
    print(f"â”‚ K-Fold CV            â”‚   {overall_kfold:.6f}     â”‚     {imp_kfold:+5.1f}%       â”‚   Ensemble    â”‚")
    print(f"â”‚ Gaussian Process     â”‚   {overall_gp:.6f}     â”‚     {imp_gp:+5.1f}%       â”‚  Uncertainty  â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")
    
    print(f"ğŸ† Best ML Method: {winner} ({winner_imp:+.1f}% improvement)\n")
    
    print("Key Findings:")
    print("  1. All ML methods outperform baseline linear regression")
    print(f"  2. Best overall: {winner} with {winner_imp:.1f}% improvement")
    print(f"  3. Neural Network best for velocities: vx ({((mae_baseline[0]-mae_nn[0])/mae_baseline[0])*100:+.1f}%)")
    print(f"  4. K-Fold provides ensemble robustness")
    print(f"  5. Gaussian Process provides Bayesian uncertainty")
    print(f"  6. Standard LMPC achieved {best_lmpc:.2f}s ({((pid_time-best_lmpc)/pid_time)*100:.1f}% vs PID)")
    
    print("\n" + "="*100)
    print("THREE-WAY COMPARISON COMPLETE! ğŸ‰")
    print("="*100 + "\n")
    
    plt.show()

if __name__== "__main__":
    main()